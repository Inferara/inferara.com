# Молоток в поисках гвоздей

В процессе разработки нового инструмента в какой-то момент неизбежно возникает
вполне резонная потребность испытать его за пределами собственной мастерской, в
неконтролируемой среде реальных задач. Наш инновационный фреймворк для
специфицирования и верификации программ **Inference** как раз подходит к этой
стадии, побуждая своих создателей примерять сей футуристичный молоток к каждому
встречному гвоздю. Однако, поскольку часов в сутках только 24, а проектов на
гитхабе, к которым, в теории, можно было бы приложить формальные методы,
существенно больше, чем имеет смысл считать, приходится каким-то образом
фильтровать потенциальный фронт работ.

По очевидным причинам, когда речь идёт о способах повышения надёжности программ,
фокусировать внимание разумно на проектах с более высокой ценой ошибки, так что
блокчейн-платформы неизбежно оказываются в начале списка - ущерб от нештатныч
ситуаций в крипто-финансовой индустрии почти всегда имеет прямую монетарную
оценку, среднее значение которой из года в год только растёт. В качестве второго
естественного критерия отсева выступает технологический стек - опытным полигоном
для нашей технологии стала механизация стандарта WebAssembly. Таким образом,
шорт-лист "гвоздей", подходящих нашему "молотку" на текущем этапе, можно
составить из блокчейн-платформ, использующих WebAssembly в качестве основного
таргета компиляции. В рамках этого разговора мы затронем три таких проекта:
Polkadot Substrate, Stellar Soroban и Arbitrum Stylus.

При взгляде на эту троицу издали в глаза бросается некоторое поверхностное
родство - все они используют Rust в качестве основного языка разработки, а
платформа WebAssembly является фундаментом их рантайма. Однако, при более
пристальном рассмотрении через оптику формальной верифицируемости начинают
проявляться фундаментальные архитектурные отличия, о которых мне и хотелось бы
здесь поговорить.

# Polkadot Substrate

Фреймворк за авторством Web3 Foundation представляет собой непрерывно
пополняющуюся коллекцию готовых решений для основных паттернов криптофинансового
учёта, организованную в виде собрания модулей специальной структуры
(`pallet`-ов) на языке Rust. Высокотехнологичная система сборки позволяет
комбинировать эти модули произвольным образом, производя тем самым на свет новые
версии рантайма, содержащие только необходимую для каждого отдельного случая
функциональность. Основные архитектурные принципы коллекции можно попытаться
сформулировать следующим образом:

1. `pallet` как универсальная единица интеграции. Любая функциональность,
которая может понадобиться блокчейн-разработчику, от отдельных аспектов
инфраструктуры до популярных паттернов бизнес-логики, предоставляется в виде
единообразно подключаемых модулей.

2. Активное использование Rust-овской системы типов и продвинутых средств
метапрограммирования в горизонтальном взаимодействии модулей для максимально
комфортного и безопасного переиспользования кода.

3. Большое внимание к оптимизации производительности рантайма с применением
наиболее мощных методик. Агрессивный инлайнинг на этапе LTO - настройка "по
умолчанию" при сборке конечного бинарника.

Сперва может показаться, что перечисленные выше качества - хвалебная ода, но, к
сожалению, у подобной архитектуры есть тёмная сторона, неизбежно вытекающая из
той же комбинации факторов, что создают её достоинства. И в тени этой, увы,
скрываются проблемы, способные, фактически, поставить крест на применимости
целого класса методов формально удостовериться в надёжности системы как в целом,
так и по частям.

Когда речь идёт о методологическом эталоне формальных методов - верификации
исполняемых бинарных модулей на уровне семантики платформы - от любой достаточно
крупной кодовой базы, подлежащей верификации, требуется ряд свойств, о которых
обычно программисты беспокоятся редко. Возникают эти требования в связи с
фундаментальными принципами рассуждений об алгоритмах и являются, по факту,
обязательными:

1. Сложные системы не верифицируемы целиком. Единственный практический способ
верификации сложных систем состоит в их разбиении и специфицировании максимально
изолированных друг от друга подсистем, верифицируемых после этого независимо
друг от друга.

2. Суммарные затраты на верификацию растут пропорционально квадрату количества
подсистем, делящих общее пространство состояний. Без чётко очерченных границ
"владений", нерушимость которых обеспечивается на уровне платформы, при
верификации приходится исходить из презумпции взаимного влияния всех на всех.

3. Переиспользование суждений о свойствах алгоритмов гораздо сложнее
переиспользования самих алгоритмов. Мономорфизация и инлайнинг, фактически,
бесплатны для разработчика и конечного пользователя, но весьма дорогостоящи в
контексте формальной верификации - каждая копия кода, произведённая этими
процедурами, становится отдельной целью, требующей самостоятельного покрытия.

В таком свете внезапно оказывается, что архитектура FRAME, к сожалению, делает
выбор в пользу усложнения задачи формальной верификации практически на каждом
повороте. Да, на уровне исходного кода система паллетов прямо-таки излучает
гибкость, модульность и удобство использования. Однако, полноценная формальная
верификация исходных кодов на языке Rust ещё долго будет оставаться утопической
мечтой (просто за отсутствием официальной спецификации его семантики), тогда как
на уровне исполняемых бинарников картина становится намного печальней.

Центральная проблема состоит в том, что все структурные границы между модулями
исходного кода полностью стираются сборочным процессом на достаточно раннем
этапе. Фактически, возможность использовать в одном паллете макроопределения из
другого эродирует их ещё на стадии препроцессинга. Если же дизассемблировать
конечный результат - официальный рантайм `polkadot`-а, скажем - результат вообще
будет представлять собой один монолитный модуль на два с лишним миллиона
инструкций, где для очень редкой функции можно однозначно установить её
принадлежность к какому-либо паллету. Хуже того, в центре этого артефакта будет
лежать одна функция на несколько сотен тысяч строк, порождённая автоматическим
инлайнингом мириады совершенно разнородных по функциональности кусков кода из
всех уголков проекта непосредственно в тело центрального диспетчера событий.

Увы, но единственное, что может сделать любой инженер по формальной верификации,
столкнувшись с таким фронтом работ - это развести руками и сдаться, поскольку
на данный момент специфицирование и доказательство корректности в подобных
условиях технологически почти невозможно, а экономически просто абсурдно. Даже
если каким-то чудом можно было бы создать всеобъемлещую и строго доказанную
спецификацию конкретной версии рантайма `polkadot`, это достижение оказалось бы
совершенно непереносимо не только на его производные форки с другим составом
включённых паллетов, но даже на следующие версии самого `polkadot`-а. Да что
там, учитывая отсутствие надёжного детерминизма в сборочном процессе Rust даже
при сэндбоксинге `docker`-ом, для инвалидации иногда достаточно будет просто
пересобрать бинарник на другой машине - из-за гонки потоков (по-видимому) при
распараллеливании компиляции, адресное пространство общей памяти и порядковая
индексация функций перемешиваются совершенно свободно.

Возможно ли малой кровью компенсировать как-то вышеперечисленные проблемы, не
производя радикального пересмотра архитектуры? Вопрос непростой, учитывая то,
сколь семимильными шагами движется прогресс в этой области. Не исключено, что
уже через считанные годы автоматизация верификации при помощи LLM позволит
просто закидать все пробемы масштаба стойкой с видеокартами. Но до той поры,
боюсь, прогноз неутешительный - попытки получить формальное подтверждение
корректности любого рантайма, наследующего кодовую базу `polkadot`, в том виде,
в котором он развёртывается и исполняется, представляются нецелесообразными.
Это не должно, однако, отвращать его пользователей и разработчиков от применения
формальных методов для повышения надёжности в меньшем масштабе - нетривиальную
арифметику в важных функциях, например, можно верифицировать на уровне
псевдокода, а изоляция контрактов в отедльных wasm-модулях позволяет
задумываться о верификации на уровне ассемблера хотя бы их.

